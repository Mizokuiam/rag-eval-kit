name: Python CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11"]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip' # cache pip dependencies

    - name: Debug - List directory contents
      run: |
        ls -la
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        
    - name: Debug - Check sample file content
      run: |
        cat sample_dataset.jsonl
        
    - name: Debug - Check package structure
      run: |
        ls -la rag_eval_kit/

    # Install the package in development mode to allow importing
    - name: Install package in development mode
      run: |
        pip install -e .

    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Check formatting with black
      run: |
        black --check .

    - name: Check import sorting with isort
      run: |
        isort --check-only .

    # - name: Run tests with pytest # Uncomment if/when tests are added
    #   run: |
    #     pytest

    - name: Debug - Python import paths
      run: |
        python -c "import sys; print(sys.path)"
        python -c "try: import rag_eval_kit; print('rag_eval_kit successfully imported'); except ImportError as e: print(f'Import error: {e}')"
        
    - name: Run evaluate script as smoke test
      run: |
        python evaluate.py sample_dataset.jsonl